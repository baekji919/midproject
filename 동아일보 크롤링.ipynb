{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import quote\n",
    "import requests\n",
    "import pandas as pd\n",
    "from lxml.html import fromstring\n",
    "import re\n",
    "\n",
    "\n",
    "url = \"https://www.donga.com/news/search?p=1&query=%EC%BD%94%EB%A1%9C%EB%82%98%EC%A0%95%EB%B6%80%EB%8C%80%EC%9D%91&check_news=1&more=1&sorting=3&search_date=5&v1=20200120&v2=20200420&range=1\"\n",
    "\n",
    "page = urlopen(url)\n",
    "soup = BeautifulSoup(page, 'html.parser')\n",
    "\n",
    "total_count_str = soup.find(\"div\",\"searchCont\").h2.span.string\n",
    "total_count_int = int(total_count_str[total_count_str.index(\"총\")+1:total_count_str.index(\"건\")])\n",
    "count = 0\n",
    "\n",
    "title_list = []\n",
    "text_total_list = []\n",
    "url_list = []\n",
    "date_list = []\n",
    "\n",
    "for i in range(1,total_count_int,15):\n",
    "    url = \"https://www.donga.com/news/search?p={}&query=%EC%BD%94%EB%A1%9C%EB%82%98%EC%A0%95%EB%B6%80%EB%8C%80%EC%9D%91&check_news=1&more=1&sorting=3&search_date=5&v1=20200120&v2=20200420&range=1\".format(i)\n",
    "    \n",
    "    page = urlopen(url)\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    \n",
    "    for search in soup.find_all('div', class_=\"searchList\"):\n",
    "        if str(search.find(\"div\",\"t\").div.em.string).strip() in [\"동아일보 > 오피니언\"]:\n",
    "            # url 데이터 수집    \n",
    "            url_list.append(str(search.find(\"div\",\"t\").p.a[\"href\"]))           \n",
    "            \n",
    "            url = search.find(\"div\",\"t\").p.a[\"href\"]\n",
    "            page = urlopen(url)\n",
    "            soup = BeautifulSoup(page, 'html.parser')\n",
    "            \n",
    "            res = requests.get(url)\n",
    "            parser = fromstring(res.text)\n",
    "            \n",
    "            # title 데이터 수집            \n",
    "            title_list.append(str(soup.find(\"div\",\"article_title\").h1.string))\n",
    "            # date 데이터 수집\n",
    "            date_list.append(soup.find(\"div\",\"title_foot\").find_all(\"span\",\"date01\")[-1].string[2:])  \n",
    "            \n",
    "            article_form = parser.xpath('//*[@id=\"content\"]/div/div[1]/text()')\n",
    "            \n",
    "            text_list = []\n",
    "            \n",
    "            for i, data in enumerate(article_form):\n",
    "                if (re.search(\"특파원.*@\",data)) or (re.search(\"기자.*@\",data)) or (re.search(\"논설위원.*@\",data)):\n",
    "                    continue\n",
    "            \n",
    "                if str(data).strip():\n",
    "                    text_list.append(str(data).strip())\n",
    "        \n",
    "            if (text_list) and (re.search(\"\\ufeff\",text_list[0])):\n",
    "                text_list[0] = text_list[0].replace(\"\\ufeff\",\"\")\n",
    "            text_total_list.append(\"\".join(text_list))\n",
    "\n",
    "df = pd.DataFrame({\"url\" : url_list,\n",
    "                  \"title\": title_list,\n",
    "                  \"date\" : date_list,\n",
    "                  \"text\" : text_total_list}, columns=[\"date\",\"title\",\"text\",\"url\"])\n",
    "\n",
    "df.to_excel(\"C:/Users/KJH/kjh/pythonwork/donga_opi.xlsx\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import quote\n",
    "import requests\n",
    "import pandas as pd\n",
    "from lxml.html import fromstring\n",
    "import re\n",
    "\n",
    "\n",
    "url = \"https://www.donga.com/news/search?p=1&query=%EC%BD%94%EB%A1%9C%EB%82%98%EC%A0%95%EB%B6%80%EB%8C%80%EC%9D%91&check_news=1&more=1&sorting=3&search_date=5&v1=20200120&v2=20200420&range=1\"\n",
    "\n",
    "page = urlopen(url)\n",
    "soup = BeautifulSoup(page, 'html.parser')\n",
    "\n",
    "total_count_str = soup.find(\"div\",\"searchCont\").h2.span.string\n",
    "total_count_int = int(total_count_str[total_count_str.index(\"총\")+1:total_count_str.index(\"건\")])\n",
    "count = 0\n",
    "\n",
    "title_list = []\n",
    "text_total_list = []\n",
    "url_list = []\n",
    "date_list = []\n",
    "\n",
    "for i in range(1,total_count_int,15):\n",
    "    url = \"https://www.donga.com/news/search?p={}&query=%EC%BD%94%EB%A1%9C%EB%82%98%EC%A0%95%EB%B6%80%EB%8C%80%EC%9D%91&check_news=1&more=1&sorting=3&search_date=5&v1=20200120&v2=20200420&range=1\".format(i)\n",
    "    \n",
    "    page = urlopen(url)\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    \n",
    "    for search in soup.find_all('div', class_=\"searchList\"):\n",
    "        if str(search.find(\"div\",\"t\").div.em.string).strip() in [\"동아일보 > 정치\"]:\n",
    "            # url 데이터 수집    \n",
    "            url_list.append(str(search.find(\"div\",\"t\").p.a[\"href\"]))           \n",
    "            \n",
    "            url = search.find(\"div\",\"t\").p.a[\"href\"]\n",
    "            page = urlopen(url)\n",
    "            soup = BeautifulSoup(page, 'html.parser')\n",
    "            \n",
    "            res = requests.get(url)\n",
    "            parser = fromstring(res.text)\n",
    "            \n",
    "            # title 데이터 수집            \n",
    "            title_list.append(str(soup.find(\"div\",\"article_title\").h1.string))\n",
    "            # date 데이터 수집\n",
    "            date_list.append(soup.find(\"div\",\"title_foot\").find_all(\"span\",\"date01\")[-1].string[2:])  \n",
    "            \n",
    "            article_form = parser.xpath('//*[@id=\"content\"]/div/div[1]/text()')\n",
    "            \n",
    "            text_list = []\n",
    "            \n",
    "            for i, data in enumerate(article_form):\n",
    "                if (re.search(\"특파원.*@\",data)) or (re.search(\"기자.*@\",data)) or (re.search(\"논설위원.*@\",data)):\n",
    "                    continue\n",
    "            \n",
    "                if str(data).strip():\n",
    "                    text_list.append(str(data).strip())\n",
    "        \n",
    "            if (text_list) and (re.search(\"\\ufeff\",text_list[0])):\n",
    "                text_list[0] = text_list[0].replace(\"\\ufeff\",\"\")\n",
    "            text_total_list.append(\"\".join(text_list))\n",
    "\n",
    "df = pd.DataFrame({\"url\" : url_list,\n",
    "                  \"title\": title_list,\n",
    "                  \"date\" : date_list,\n",
    "                  \"text\" : text_total_list}, columns=[\"date\",\"title\",\"text\",\"url\"])\n",
    "\n",
    "df.to_excel(\"C:/Users/KJH/kjh/pythonwork/donga_pol.xlsx\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(title_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.donga.com/news/search?p=1&query=%EB%A9%94%EB%A5%B4%EC%8A%A4%EC%A0%95%EB%B6%80%EB%8C%80%EC%9D%91&check_news=1&more=1&sorting=1&search_date=5&v1=20150520&v2=20150820&range=1\n",
      "동아일보 > 오피니언\n",
      "동아일보 > 오피니언\n",
      "https://www.donga.com/news/search?p=16&query=%EB%A9%94%EB%A5%B4%EC%8A%A4%EC%A0%95%EB%B6%80%EB%8C%80%EC%9D%91&check_news=1&more=1&sorting=1&search_date=5&v1=20150520&v2=20150820&range=1\n",
      "동아일보 > 오피니언\n",
      "https://www.donga.com/news/search?p=31&query=%EB%A9%94%EB%A5%B4%EC%8A%A4%EC%A0%95%EB%B6%80%EB%8C%80%EC%9D%91&check_news=1&more=1&sorting=1&search_date=5&v1=20150520&v2=20150820&range=1\n",
      "동아일보 > 오피니언\n",
      "동아일보 > 오피니언\n",
      "https://www.donga.com/news/search?p=46&query=%EB%A9%94%EB%A5%B4%EC%8A%A4%EC%A0%95%EB%B6%80%EB%8C%80%EC%9D%91&check_news=1&more=1&sorting=1&search_date=5&v1=20150520&v2=20150820&range=1\n",
      "동아일보 > 오피니언\n",
      "https://www.donga.com/news/search?p=61&query=%EB%A9%94%EB%A5%B4%EC%8A%A4%EC%A0%95%EB%B6%80%EB%8C%80%EC%9D%91&check_news=1&more=1&sorting=1&search_date=5&v1=20150520&v2=20150820&range=1\n",
      "https://www.donga.com/news/search?p=76&query=%EB%A9%94%EB%A5%B4%EC%8A%A4%EC%A0%95%EB%B6%80%EB%8C%80%EC%9D%91&check_news=1&more=1&sorting=1&search_date=5&v1=20150520&v2=20150820&range=1\n",
      "동아일보 > 오피니언\n",
      "동아일보 > 오피니언\n",
      "https://www.donga.com/news/search?p=91&query=%EB%A9%94%EB%A5%B4%EC%8A%A4%EC%A0%95%EB%B6%80%EB%8C%80%EC%9D%91&check_news=1&more=1&sorting=1&search_date=5&v1=20150520&v2=20150820&range=1\n",
      "동아일보 > 오피니언\n",
      "https://www.donga.com/news/search?p=106&query=%EB%A9%94%EB%A5%B4%EC%8A%A4%EC%A0%95%EB%B6%80%EB%8C%80%EC%9D%91&check_news=1&more=1&sorting=1&search_date=5&v1=20150520&v2=20150820&range=1\n",
      "동아일보 > 오피니언\n",
      "https://www.donga.com/news/search?p=121&query=%EB%A9%94%EB%A5%B4%EC%8A%A4%EC%A0%95%EB%B6%80%EB%8C%80%EC%9D%91&check_news=1&more=1&sorting=1&search_date=5&v1=20150520&v2=20150820&range=1\n",
      "동아일보 > 오피니언\n",
      "https://www.donga.com/news/search?p=136&query=%EB%A9%94%EB%A5%B4%EC%8A%A4%EC%A0%95%EB%B6%80%EB%8C%80%EC%9D%91&check_news=1&more=1&sorting=1&search_date=5&v1=20150520&v2=20150820&range=1\n",
      "https://www.donga.com/news/search?p=151&query=%EB%A9%94%EB%A5%B4%EC%8A%A4%EC%A0%95%EB%B6%80%EB%8C%80%EC%9D%91&check_news=1&more=1&sorting=1&search_date=5&v1=20150520&v2=20150820&range=1\n",
      "동아일보 > 오피니언\n",
      "https://www.donga.com/news/search?p=166&query=%EB%A9%94%EB%A5%B4%EC%8A%A4%EC%A0%95%EB%B6%80%EB%8C%80%EC%9D%91&check_news=1&more=1&sorting=1&search_date=5&v1=20150520&v2=20150820&range=1\n",
      "https://www.donga.com/news/search?p=181&query=%EB%A9%94%EB%A5%B4%EC%8A%A4%EC%A0%95%EB%B6%80%EB%8C%80%EC%9D%91&check_news=1&more=1&sorting=1&search_date=5&v1=20150520&v2=20150820&range=1\n",
      "동아일보 > 오피니언\n",
      "https://www.donga.com/news/search?p=196&query=%EB%A9%94%EB%A5%B4%EC%8A%A4%EC%A0%95%EB%B6%80%EB%8C%80%EC%9D%91&check_news=1&more=1&sorting=1&search_date=5&v1=20150520&v2=20150820&range=1\n",
      "https://www.donga.com/news/search?p=211&query=%EB%A9%94%EB%A5%B4%EC%8A%A4%EC%A0%95%EB%B6%80%EB%8C%80%EC%9D%91&check_news=1&more=1&sorting=1&search_date=5&v1=20150520&v2=20150820&range=1\n",
      "https://www.donga.com/news/search?p=226&query=%EB%A9%94%EB%A5%B4%EC%8A%A4%EC%A0%95%EB%B6%80%EB%8C%80%EC%9D%91&check_news=1&more=1&sorting=1&search_date=5&v1=20150520&v2=20150820&range=1\n",
      "동아일보 > 오피니언\n",
      "https://www.donga.com/news/search?p=241&query=%EB%A9%94%EB%A5%B4%EC%8A%A4%EC%A0%95%EB%B6%80%EB%8C%80%EC%9D%91&check_news=1&more=1&sorting=1&search_date=5&v1=20150520&v2=20150820&range=1\n",
      "https://www.donga.com/news/search?p=256&query=%EB%A9%94%EB%A5%B4%EC%8A%A4%EC%A0%95%EB%B6%80%EB%8C%80%EC%9D%91&check_news=1&more=1&sorting=1&search_date=5&v1=20150520&v2=20150820&range=1\n",
      "https://www.donga.com/news/search?p=271&query=%EB%A9%94%EB%A5%B4%EC%8A%A4%EC%A0%95%EB%B6%80%EB%8C%80%EC%9D%91&check_news=1&more=1&sorting=1&search_date=5&v1=20150520&v2=20150820&range=1\n",
      "동아일보 > 오피니언\n",
      "동아일보 > 오피니언\n",
      "https://www.donga.com/news/search?p=286&query=%EB%A9%94%EB%A5%B4%EC%8A%A4%EC%A0%95%EB%B6%80%EB%8C%80%EC%9D%91&check_news=1&more=1&sorting=1&search_date=5&v1=20150520&v2=20150820&range=1\n",
      "https://www.donga.com/news/search?p=301&query=%EB%A9%94%EB%A5%B4%EC%8A%A4%EC%A0%95%EB%B6%80%EB%8C%80%EC%9D%91&check_news=1&more=1&sorting=1&search_date=5&v1=20150520&v2=20150820&range=1\n",
      "https://www.donga.com/news/search?p=316&query=%EB%A9%94%EB%A5%B4%EC%8A%A4%EC%A0%95%EB%B6%80%EB%8C%80%EC%9D%91&check_news=1&more=1&sorting=1&search_date=5&v1=20150520&v2=20150820&range=1\n",
      "https://www.donga.com/news/search?p=331&query=%EB%A9%94%EB%A5%B4%EC%8A%A4%EC%A0%95%EB%B6%80%EB%8C%80%EC%9D%91&check_news=1&more=1&sorting=1&search_date=5&v1=20150520&v2=20150820&range=1\n",
      "https://www.donga.com/news/search?p=346&query=%EB%A9%94%EB%A5%B4%EC%8A%A4%EC%A0%95%EB%B6%80%EB%8C%80%EC%9D%91&check_news=1&more=1&sorting=1&search_date=5&v1=20150520&v2=20150820&range=1\n",
      "동아일보 > 오피니언\n",
      "동아일보 > 오피니언\n",
      "https://www.donga.com/news/search?p=361&query=%EB%A9%94%EB%A5%B4%EC%8A%A4%EC%A0%95%EB%B6%80%EB%8C%80%EC%9D%91&check_news=1&more=1&sorting=1&search_date=5&v1=20150520&v2=20150820&range=1\n",
      "https://www.donga.com/news/search?p=376&query=%EB%A9%94%EB%A5%B4%EC%8A%A4%EC%A0%95%EB%B6%80%EB%8C%80%EC%9D%91&check_news=1&more=1&sorting=1&search_date=5&v1=20150520&v2=20150820&range=1\n",
      "https://www.donga.com/news/search?p=391&query=%EB%A9%94%EB%A5%B4%EC%8A%A4%EC%A0%95%EB%B6%80%EB%8C%80%EC%9D%91&check_news=1&more=1&sorting=1&search_date=5&v1=20150520&v2=20150820&range=1\n",
      "https://www.donga.com/news/search?p=406&query=%EB%A9%94%EB%A5%B4%EC%8A%A4%EC%A0%95%EB%B6%80%EB%8C%80%EC%9D%91&check_news=1&more=1&sorting=1&search_date=5&v1=20150520&v2=20150820&range=1\n",
      "동아일보 > 오피니언\n",
      "https://www.donga.com/news/search?p=421&query=%EB%A9%94%EB%A5%B4%EC%8A%A4%EC%A0%95%EB%B6%80%EB%8C%80%EC%9D%91&check_news=1&more=1&sorting=1&search_date=5&v1=20150520&v2=20150820&range=1\n",
      "동아일보 > 오피니언\n"
     ]
    }
   ],
   "source": [
    "# (2015/05/20 ~ 2015/08/20) 메르스정부대응  \n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import requests\n",
    "import pandas as pd\n",
    "from lxml.html import fromstring\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# 첫 페이지 접근\n",
    "url = \"https://www.donga.com/news/search?p=1&query=%EB%A9%94%EB%A5%B4%EC%8A%A4%EC%A0%95%EB%B6%80%EB%8C%80%EC%9D%91&check_news=1&more=1&sorting=1&search_date=5&v1=20150520&v2=20150820&range=1\"\n",
    "\n",
    "page = urlopen(url)\n",
    "soup = BeautifulSoup(page, 'html.parser')\n",
    "\n",
    "# (문자열) 총 뉴스 건수\n",
    "total_count_str = soup.find(\"div\",\"searchCont\").h2.span.string\n",
    "# (숫자) 총 뉴스 건수 \n",
    "total_count_int = int(total_count_str[total_count_str.index(\"총\")+1:total_count_str.index(\"건\")])\n",
    "\n",
    "# 타이틀 리스트\n",
    "title_list = []\n",
    "# 뉴스내용 리스트\n",
    "text_total_list = []\n",
    "# URL 리스트\n",
    "url_list = []\n",
    "# 뉴스 작성일자 리스트\n",
    "date_list = []\n",
    "\n",
    "# 한 페이지 당 최대 15개 뉴스\n",
    "for i in range(1,total_count_int,15):\n",
    "    url = \"https://www.donga.com/news/search?p={}&query=%EB%A9%94%EB%A5%B4%EC%8A%A4%EC%A0%95%EB%B6%80%EB%8C%80%EC%9D%91&check_news=1&more=1&sorting=1&search_date=5&v1=20150520&v2=20150820&range=1\".format(i)\n",
    "    page = urlopen(url)\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    print(url)\n",
    "    # 각 뉴스 페이지 접근 전 상위 페이지 접근       \n",
    "    for search in soup.find_all('div', class_=\"searchList\"):\n",
    "        \n",
    "        if not search.find(\"div\",\"t\").div:\n",
    "            continue\n",
    "        \n",
    "        if str(search.find(\"div\",\"t\").div.em.string).strip() in [\"동아일보 > 오피니언\"]:\n",
    "            print(str(search.find(\"div\",\"t\").div.em.string).strip())\n",
    "            url = search.find(\"div\",\"t\").p.a[\"href\"]\n",
    "            page = urlopen(url)\n",
    "            soup = BeautifulSoup(page, 'html.parser')\n",
    "            \n",
    "            res = requests.get(url)\n",
    "            parser = fromstring(res.text)\n",
    "            \n",
    "            # url 데이터 수집    \n",
    "            url_list.append(str(search.find(\"div\",\"t\").p.a[\"href\"])) \n",
    "            # title 데이터 수집            \n",
    "            title_list.append(str(soup.find(\"div\",\"article_title\").h1.string))\n",
    "            # date 데이터 수집\n",
    "            date_list.append(soup.find(\"div\",\"title_foot\").find_all(\"span\",\"date01\")[-1].string[2:])  \n",
    "            \n",
    "            article_form = parser.xpath('//*[@id=\"content\"]/div/div[1]/text()')\n",
    "            text_list = []\n",
    "            \n",
    "            for i, data in enumerate(article_form):\n",
    "                # 기사 내용 중 특파원, 기자, 논설위원 작성 부분 스킵           \n",
    "                if (re.search(\"특파원.*@\",data)) or (re.search(\"기자.*@\",data)) or (re.search(\"논설위원.*@\",data)):\n",
    "                    continue\n",
    "                    \n",
    "                # 공백없는 데이터만 기사내용으로 삽입\n",
    "                if str(data).strip():\n",
    "                    text_list.append(str(data).strip())\n",
    "            # 기사 내용이 있고, 기사내용 시작이 유니코드인 데이터 수정 후 삽입            \n",
    "            if (text_list) and (re.search(\"\\ufeff\",text_list[0])):\n",
    "                text_list[0] = text_list[0].replace(\"\\ufeff\",\"\")\n",
    "            # 리스트 형태로 작성된 기사내용을 문자열로 변환            \n",
    "            text_total_list.append(\"\".join(text_list))\n",
    "\n",
    "# 기사(타이틀, 날짜, URL, 기사내용) 데이터를 데이터프레임 형식으로 생성\n",
    "df = pd.DataFrame({\"url\" : url_list,\n",
    "                  \"title\": title_list,\n",
    "                  \"date\" : date_list,\n",
    "                  \"text\" : text_total_list}, columns=[\"date\",\"title\",\"text\",\"url\"])\n",
    "\n",
    "# 엑셀파일(xlsx) 형식으로 기사(타이틀, 날짜, URL, 기사내용) 저장\n",
    "df.to_excel(\"C:/Users/KJH/kjh/pythonwork/donga_mers_opi.xlsx\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2015/05/20 ~ 2015/08/20) 메르스정부대응  \n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import requests\n",
    "import pandas as pd\n",
    "from lxml.html import fromstring\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# 첫 페이지 접근\n",
    "url = \"https://www.donga.com/news/search?p=1&query=%EB%A9%94%EB%A5%B4%EC%8A%A4%EC%A0%95%EB%B6%80%EB%8C%80%EC%9D%91&check_news=1&more=1&sorting=1&search_date=5&v1=20150520&v2=20150820&range=1\"\n",
    "\n",
    "page = urlopen(url)\n",
    "soup = BeautifulSoup(page, 'html.parser')\n",
    "\n",
    "# (문자열) 총 뉴스 건수\n",
    "total_count_str = soup.find(\"div\",\"searchCont\").h2.span.string\n",
    "# (숫자) 총 뉴스 건수 \n",
    "total_count_int = int(total_count_str[total_count_str.index(\"총\")+1:total_count_str.index(\"건\")])\n",
    "\n",
    "# 타이틀 리스트\n",
    "title_list = []\n",
    "# 뉴스내용 리스트\n",
    "text_total_list = []\n",
    "# URL 리스트\n",
    "url_list = []\n",
    "# 뉴스 작성일자 리스트\n",
    "date_list = []\n",
    "\n",
    "# 한 페이지 당 최대 15개 뉴스\n",
    "for i in range(1,total_count_int,15):\n",
    "    url = \"https://www.donga.com/news/search?p={}&query=%EB%A9%94%EB%A5%B4%EC%8A%A4%EC%A0%95%EB%B6%80%EB%8C%80%EC%9D%91&check_news=1&more=1&sorting=1&search_date=5&v1=20150520&v2=20150820&range=1\".format(i)\n",
    "    page = urlopen(url)\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    print(url)\n",
    "    # 각 뉴스 페이지 접근 전 상위 페이지 접근       \n",
    "    for search in soup.find_all('div', class_=\"searchList\"):\n",
    "        \n",
    "        if not search.find(\"div\",\"t\").div:\n",
    "            continue\n",
    "        \n",
    "        if str(search.find(\"div\",\"t\").div.em.string).strip() in [\"동아일보 > 정치\"]:\n",
    "            print(str(search.find(\"div\",\"t\").div.em.string).strip())\n",
    "            url = search.find(\"div\",\"t\").p.a[\"href\"]\n",
    "            page = urlopen(url)\n",
    "            soup = BeautifulSoup(page, 'html.parser')\n",
    "            \n",
    "            res = requests.get(url)\n",
    "            parser = fromstring(res.text)\n",
    "            \n",
    "            # url 데이터 수집    \n",
    "            url_list.append(str(search.find(\"div\",\"t\").p.a[\"href\"])) \n",
    "            # title 데이터 수집            \n",
    "            title_list.append(str(soup.find(\"div\",\"article_title\").h1.string))\n",
    "            # date 데이터 수집\n",
    "            date_list.append(soup.find(\"div\",\"title_foot\").find_all(\"span\",\"date01\")[-1].string[2:])  \n",
    "            \n",
    "            article_form = parser.xpath('//*[@id=\"content\"]/div/div[1]/text()')\n",
    "            text_list = []\n",
    "            \n",
    "            for i, data in enumerate(article_form):\n",
    "                # 기사 내용 중 특파원, 기자, 논설위원 작성 부분 스킵           \n",
    "                if (re.search(\"특파원.*@\",data)) or (re.search(\"기자.*@\",data)) or (re.search(\"논설위원.*@\",data)):\n",
    "                    continue\n",
    "                    \n",
    "                # 공백없는 데이터만 기사내용으로 삽입\n",
    "                if str(data).strip():\n",
    "                    text_list.append(str(data).strip())\n",
    "            # 기사 내용이 있고, 기사내용 시작이 유니코드인 데이터 수정 후 삽입            \n",
    "            if (text_list) and (re.search(\"\\ufeff\",text_list[0])):\n",
    "                text_list[0] = text_list[0].replace(\"\\ufeff\",\"\")\n",
    "            # 리스트 형태로 작성된 기사내용을 문자열로 변환            \n",
    "            text_total_list.append(\"\".join(text_list))\n",
    "\n",
    "# 기사(타이틀, 날짜, URL, 기사내용) 데이터를 데이터프레임 형식으로 생성\n",
    "df = pd.DataFrame({\"url\" : url_list,\n",
    "                  \"title\": title_list,\n",
    "                  \"date\" : date_list,\n",
    "                  \"text\" : text_total_list}, columns=[\"date\",\"title\",\"text\",\"url\"])\n",
    "\n",
    "# 엑셀파일(xlsx) 형식으로 기사(타이틀, 날짜, URL, 기사내용) 저장\n",
    "df.to_excel(\"C:/Users/KJH/kjh/pythonwork/donga_mers_pol.xlsx\",index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
